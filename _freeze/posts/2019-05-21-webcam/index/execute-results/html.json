{
  "hash": "f7c47b7766c1918ad7da36ce8002ed47",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Webcam Image Classification\"\ndate: 2019-05-21\nslug: webcam-image-classification\ncategories:\n  - Javascript\nengine: knitr\nimage: thumbnail.png\n---\n\nAs I mentioned in my [\"Hello World\"](/posts/2019-05-07-hello_world/) post, I'm fascinated with computer vision. I'm in the process of writing up a post about the image classification mobile app that I made to detect whether my iPhone camera is pointing at my dog or not. While trying to figure out how to host a live ML model within a browser, I learned how to call pre-trained Tensorflow models from the HTML `<script>` tag. This option is pretty straightforward, but required learning a bit of JavaScript. If I tried to do this strictly in R, I anticipated embedding a Shiny application with an upload photo UI, pre-loaded model, image display, etc.\n\nIn this post, I create a webcam image classifier using a pre-trained TensorFlow.js MobileNet model hosted on [jsDelivr](https://www.jsdelivr.com/). MobileNets are relatively small neural networks that are optimized to work well on less powerful computers (e.g. cell phones, tablets). This increased efficiency comes with a tradeoff in accuracy. Depending on the exact architecture chosen, MobileNets tend to top out around 60-70% accuracy. This particular model can predict [1,000 different classes](https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/imagenet_classes.ts), mostly commonplace objects and animals. I've found that it gets confused when the background is non-monochromatic, so for best results try to position the object in front of something simple. Before diving into the code, I am by no means a front end developer, so forgive the weak UI and delay in classification and display of the results. Below is the final product, followed by the instructions to recreate it. Have fun!\n\npreservea4c35e15549da6c8\n\n### How it's made:\n\nThe first step is to load the necessary libraries:\n\n-   TensorFlow.js to run the model\n-   The MobileNet model to classify the images\n-   D3.js for visualization\n\n\n::: {.cell}\n\n```{.js .cell-code}\n<!-- Load TensorFlow.js. This is required to use MobileNet. -->\n<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.1\"></script>\n<!-- Load the MobileNet model. -->\n<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.1\"></script>\n<!-- Load D3 for the visualization of predicted image classifications -->\n<script src=\"https://d3js.org/d3.v4.min.js\"></script>\n```\n:::\n\n\n<!-- Load TensorFlow.js. This is required to use MobileNet. -->\n\n```{=html}\n<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.1\"></script>\n```\n<!-- Load the MobileNet model. -->\n\n```{=html}\n<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.1\"></script>\n```\n<!-- Load D3 for the visualization of predicted image classifications -->\n\n```{=html}\n<script src=\"https://d3js.org/d3.v4.min.js\"></script>\n```\nI add some (bare minimum) CSS so that the UI is somewhat presentable.\n\n\n::: {.cell}\n\n```{.css .cell-code}\n<style>\n.bar {\n    fill: #27A822;\n}\n.axis {\n    font-size: 10px;\n}\n.axis path,\n.axis line {\n    fill: none;\n    display: none;\n}\n.label {\n    font-size: 13px;\n}\n.column {\n  float: left;\n  width: 33.33%;\n}\n.row:after {\n  content: \"\";\n  display: table;\n  clear: both;\n}\n</style>\n```\n:::\n\n\n```{=html}\n<style>\n.bar {\n    fill: #27A822;\n}\n.axis {\n    font-size: 10px;\n}\n.axis path,\n.axis line {\n    fill: none;\n    display: none;\n}\n.label {\n    font-size: 13px;\n}\n.column {\n  float: left;\n  width: 33.33%;\n}\n.row:after {\n  content: \"\";\n  display: table;\n  clear: both;\n}\n</style>\n```\n\n::: {.cell}\n<script>\n// Initialize webcam and image settings\nconst constraints = {\n  video: true\n};\nconst captureVideoButton = document.getElementById('capture-button');\nconst screenshotButton = document.getElementById('screenshot-button');\nconst img = document.getElementById('screenshot-img');\nconst video = document.querySelector('video');\nconst canvas = document.createElement('canvas');\n\n// Set the dimensions and margins of the graph\nvar margin = {top: 0, right: 0, bottom: 25, left: 110},\n    width = 240 - margin.left - margin.right,\n    height = 180 - margin.top - margin.bottom;\n\n// Create the graph with the dimensions set above\nvar svg = d3.select(\"#graphic\").append(\"svg\")\n        .attr(\"width\", width + margin.left + margin.right)\n        .attr(\"height\", height + margin.top + margin.bottom)\n      .append(\"g\")\n        .attr(\"transform\", \n              \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n// Set the range of y and x\nvar y = d3.scaleBand()\n          .range([height, 0])\n          .padding(0.1);\n\nvar x = d3.scaleLinear()\n          .range([0, width]);\n\n// Initialize the axes with the x-axis formatted as a percentage     \nvar xAxis = d3.axisBottom(x)\n              .ticks(4)\n              .tickFormat(d => Math.round(d*100) + \"%\");\nvar yAxis = d3.axisLeft(y);\n\n// Attach the settings for the axes\nsvg.append(\"g\")\n    .attr(\"class\", \"y axis\")\n    .call(yAxis);\nsvg.append(\"g\")\n    .attr(\"class\", \"x axis\");\n    \n// When the video button is clicked, open the video webcam and begin streaming\ncaptureVideoButton.onclick = function() {\n  navigator.mediaDevices.getUserMedia(constraints).\n    then(handleSuccess).catch(handleError);\n};\n    \nfunction wrap(text, width) {\n  text.each(function() {\n    var text = d3.select(this),\n        words = text.text().split(/\\s+/).reverse(),\n        word,\n        line = [],\n        lineNumber = 0,\n        lineHeight = 0.5, // ems\n        y = text.attr(\"y\"),\n        dy = parseFloat(text.attr(\"dy\")),\n        tspan = text.text(null).append(\"tspan\").attr(\"x\", -10).attr(\"y\", y).attr(\"dy\", dy + \"em\")\n    while (word = words.pop()) {\n      line.push(word)\n      tspan.text(line.join(\" \"))\n      if (tspan.node().getComputedTextLength() > width) {\n        line.pop()\n        tspan.text(line.join(\" \"))\n        line = [word]\n        tspan = text.append(\"tspan\")\n                        .attr(\"x\", -10)\n                        .attr(\"y\", y)\n                        .attr(\"dy\", `${++lineNumber * lineHeight + dy}em`)\n                        .text(word)\n      }\n    }\n  })\n};\n    \nfunction update(data) {\n    \n  // Sort bars based on value\n  data = data.sort(function (a, b) { \n      return d3.ascending(a.probability, b.probability);\n  });\n  \n  // Format the data\n  data.forEach(function(d) {\n    d.probability = +d.probability;\n  });\n\n  // Scale the range of the data in the domains\n  x.domain([0, d3.max(data, function(d){ return d.probability; })])\n  y.domain(data.map(function(d) { return d.className; }));\n\n  // Remove any existing bars on the graph\n  var bars = svg.selectAll(\".bar\")\n      .remove()\n      .exit()\n      .data(data)\n  \n  // Add new bars using the new data\n  bars.enter()\n      .append(\"rect\")\n      .attr(\"class\", \"bar\")\n      .attr(\"width\", function(d) {return x(d.probability); } )\n      .attr(\"y\", function(d) { return y(d.className); })\n      .attr(\"height\", y.bandwidth());\n\n  // Add the x Axis\n  svg.select(\".x\")\n      .attr(\"transform\", \"translate(0,\" + height + \")\")\n      .call(d3.axisBottom(x)\n              .ticks(4)\n              .tickFormat(d => Math.round(d*100) + \"%\"));\n\n  // Add the y Axis\n  svg.select(\".y\")\n      .call(d3.axisLeft(y))\n    .selectAll(\".tick text\")\n      .call(wrap, 100);\n};\n\n// When the screenshot button or the video itself is clicked,\n// grab a still image of the stream and replace the blank canvas\nscreenshotButton.onclick = video.onclick = function() {\n  \n  canvas.width = video.videoWidth;\n  canvas.height = video.videoHeight;\n  canvas.getContext('2d').drawImage(video, 0, 0);\n  // Other browsers will fall back to image/png\n  img.src = canvas.toDataURL('image/webp');\n  \n  const img_tmp = document.getElementById('screenshot-img');\n  \n  // Load the model\n  mobilenet.load().then(model => {\n    // Classify the image\n    model.classify(img_tmp).then(predictions => {\n      // Update the bar chart\n      update(predictions);\n    });\n  });\n};\n\nfunction handleSuccess(stream) {\n  screenshotButton.disabled = false;\n  video.srcObject = stream;\n};\n</script>\n:::\n\n\nNext, I add a basic UI with a \"Capture video\" and \"Take screenshot\" button that will start the webcam and screenshot a single frame to initiate object classification, respectively.\n\n``` html\n<p align=\"center\">\n  <button id=\"capture-button\" class=\"capture-button\">Capture video</button>\n  <button id=\"screenshot-button\" disabled>Take screenshot</button>\n</p>\n<br>\n<div class=\"row\">\n  <div class=\"column\">\n    <video class=\"videostream\" width=\"240\" height=\"180\" autoplay></video>\n  </div>\n  <div class=\"column\">\n    <img id=\"screenshot-img\" width=\"240\" height=\"180\">\n  </div>\n  <div class=\"column\">\n    <div id=\"graphic\" align=\"center\" width=\"240\" height=\"180\"></div>\n  </div>\n</div>\n```\n\nNow that the UI is all set up, you need to make it react to input. To start, I initialize several variables that will be used later by the webcam. I also set up the size and axes of the graph that will ultimately display the top 3 classes and corresponding probabilities that the MobileNet predicts for the object in the still screenshot.\n\n\n::: {.cell}\n\n```{.js .cell-code}\n// Initialize webcam and image settings\nconst constraints = {\n  video: true\n};\nconst captureVideoButton = document.getElementById('capture-button');\nconst screenshotButton = document.getElementById('screenshot-button');\nconst img = document.getElementById('screenshot-img');\nconst video = document.querySelector('video');\nconst canvas = document.createElement('canvas');\n\n// Set the dimensions and margins of the graph\nvar margin = {top: 0, right: 0, bottom: 25, left: 110},\n    width = 240 - margin.left - margin.right,\n    height = 180 - margin.top - margin.bottom;\n\n// Create the graph with the dimensions set above\nvar svg = d3.select(\"#graphic\").append(\"svg\")\n        .attr(\"width\", width + margin.left + margin.right)\n        .attr(\"height\", height + margin.top + margin.bottom)\n      .append(\"g\")\n        .attr(\"transform\", \n              \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n// Set the range of y and x\nvar y = d3.scaleBand()\n          .range([height, 0])\n          .padding(0.1);\n\nvar x = d3.scaleLinear()\n          .range([0, width]);\n\n// Initialize the axes with the x-axis formatted as a percentage     \nvar xAxis = d3.axisBottom(x)\n              .ticks(4)\n              .tickFormat(d => Math.round(d*100) + \"%\");\nvar yAxis = d3.axisLeft(y);\n\n// Attach the settings for the axes\nsvg.append(\"g\")\n    .attr(\"class\", \"y axis\")\n    .call(yAxis);\nsvg.append(\"g\")\n    .attr(\"class\", \"x axis\");\n```\n:::\n\n\nBecause I decided to put the videostream, screenshot, and graph all on the same row of the site, the y-axis labels tended to get cut off, especially when the predicted class is something like \"cellular telephone, cellular phone, cellphone, cell, mobile phone\". This next function was taken almost directly from [here](https://bl.ocks.org/mbostock/7555321) with minor tweaks to work on a horizontal bar chart rather than a vertical one. It takes text and a fixed width and splits it over several lines.\n\n\n::: {.cell}\n\n```{.js .cell-code}\nfunction wrap(text, width) {\n  text.each(function() {\n    var text = d3.select(this),\n        words = text.text().split(/\\s+/).reverse(),\n        word,\n        line = [],\n        lineNumber = 0,\n        lineHeight = 0.5, // ems\n        y = text.attr(\"y\"),\n        dy = parseFloat(text.attr(\"dy\")),\n        tspan = text.text(null).append(\"tspan\").attr(\"x\", -10).attr(\"y\", y).attr(\"dy\", dy + \"em\")\n    while (word = words.pop()) {\n      line.push(word)\n      tspan.text(line.join(\" \"))\n      if (tspan.node().getComputedTextLength() > width) {\n        line.pop()\n        tspan.text(line.join(\" \"))\n        line = [word]\n        tspan = text.append(\"tspan\")\n                        .attr(\"x\", -10)\n                        .attr(\"y\", y)\n                        .attr(\"dy\", `${++lineNumber * lineHeight + dy}em`)\n                        .text(word)\n      }\n    }\n  })\n}\n```\n:::\n\n\nThe last function related to the D3.js graph is below. It updates the existing graph with the data it receives anytime it is called. It's all pretty self-explanatory, so see the comments within the function.\n\n\n::: {.cell}\n\n```{.js .cell-code}\nfunction update(data) {\n    \n    // Sort bars based on value\n    data = data.sort(function (a, b) { \n        return d3.ascending(a.probability, b.probability);\n    });\n    \n    // Format the data\n    data.forEach(function(d) {\n      d.probability = +d.probability;\n    });\n  \n    // Scale the range of the data in the domains\n    x.domain([0, d3.max(data, function(d){ return d.probability; })])\n    y.domain(data.map(function(d) { return d.className; }));\n  \n    // Remove any existing bars on the graph\n    var bars = svg.selectAll(\".bar\")\n        .remove()\n        .exit()\n        .data(data)\n    \n    // Add new bars using the new data\n    bars.enter()\n        .append(\"rect\")\n        .attr(\"class\", \"bar\")\n        .attr(\"width\", function(d) {return x(d.probability); } )\n        .attr(\"y\", function(d) { return y(d.className); })\n        .attr(\"height\", y.bandwidth());\n  \n    // Add the x Axis\n    svg.select(\".x\")\n        .attr(\"transform\", \"translate(0,\" + height + \")\")\n        .call(d3.axisBottom(x)\n                .ticks(4)\n                .tickFormat(d => Math.round(d*100) + \"%\"));\n  \n    // Add the y Axis\n    svg.select(\".y\")\n        .call(d3.axisLeft(y))\n      .selectAll(\".tick text\")\n        .call(wrap, 100);\n}\n```\n:::\n\n\n<br>\n\nSo far, I've set up the UI and the code to create the graph, but have not set up either the webcam or screenshot mechanism. In the next code chunk, I capture the video stream on button click using the `getUserMedia()` API. [HTML5rocks.com](https://www.html5rocks.com/en/tutorials/getusermedia/intro/) has a very helpful article on video and audio capturing, if you're interested in learning more. Next, I update the canvas element acting as the placeholder for the screenshot. That screenshot image then gets fed into the MobileNet model and the resulting predictions are passed in as the data to the `update()` function I wrote above.\n\n\n::: {.cell}\n\n```{.js .cell-code}\n// When the video button is clicked, open the video webcam and begin streaming\ncaptureVideoButton.onclick = function() {\n  navigator.mediaDevices.getUserMedia(constraints).\n    then(handleSuccess).catch(handleError);\n};\n\nfunction handleSuccess(stream) {\n  screenshotButton.disabled = false;\n  video.srcObject = stream;\n};\n\n// When the screenshot button or the video itself is clicked,\n// grab a still image of the stream and replace the blank canvas\nscreenshotButton.onclick = video.onclick = function() {\n  \n  canvas.width = video.videoWidth;\n  canvas.height = video.videoHeight;\n  canvas.getContext('2d').drawImage(video, 0, 0);\n  // Other browsers will fall back to image/png\n  img.src = canvas.toDataURL('image/webp');\n  \n  const img_tmp = document.getElementById('screenshot-img');\n  \n  // Load the model\n  mobilenet.load().then(model => {\n    \n    // Classify the image\n    model.classify(img_tmp).then(predictions => {\n      \n      // Update the bar chart\n      update(predictions);\n            \n    });\n  });\n};\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {
      "preservea4c35e15549da6c8": "\n<center><h3>The final product!</h3></center>\n<p align=\"center\">\n  <button id=\"capture-button\" class=\"capture-button\">Capture video</button>\n  <button id=\"screenshot-button\" disabled>Take screenshot</button>\n</p>\n<br>\n<div class=\"row\">\n  <div class=\"column\">\n    <video class=\"videostream\" width=\"100%\" height=\"180\" autoplay></video>\n  </div>\n  <div class=\"column\">\n    <img id=\"screenshot-img\" width=\"100%\" height=\"180\">\n  </div>\n  <div class=\"column\">\n    <div id=\"graphic\" align=\"center\" width=\"100%\" height=\"180\"></div>\n  </div>\n</div>\n"
    },
    "postProcess": true
  }
}